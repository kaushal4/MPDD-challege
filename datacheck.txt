--- Starting Data Inspection using 'config.json' ---

Loaded Configuration:
  Data Root: ../MPDD-2025/MPDD-Elderly
  Window Time: 1s
  Audio Features: wav2vec
  Video Features: openface
  Label Count: 2
  Max Seq Len: 26
  Batch Size: 2

Validating paths from config...
  Checking DEV_JSON: ../MPDD-2025/MPDD-Elderly/Training/labels/Training_Validation_files.json ... Found
  Checking PERS_FEAT: ../MPDD-2025/MPDD-Elderly/Training/individualEmbedding/descriptions_embeddings_with_ids.npy ... Found
  Checking AUDIO_DIR: ../MPDD-2025/MPDD-Elderly/Training/1s/Audio/wav2vec ... Found
  Checking VIDEO_DIR: ../MPDD-2025/MPDD-Elderly/Training/1s/Visual/openface ... Found

Loading training data definitions from: ../MPDD-2025/MPDD-Elderly/Training/labels/Training_Validation_files.json
Found 337 entries in the JSON.

Creating Dataset instance...
Dataset created successfully with 337 items.
Creating DataLoader instance...

--- Checking first 10 batches (Batch Size: 2) ---

--- Analyzing Batch 0 ---
  A_feat - Shape: torch.Size([2, 26, 512]), Dtype: torch.float32, Device: cpu
  A_feat - Stats: Min=0.0000, Max=2.4519, Mean=0.0655, Std=0.1362
  V_feat - Shape: torch.Size([2, 26, 709]), Dtype: torch.float32, Device: cpu
  V_feat - Stats: Min=-110.7533, Max=1431.7300, Mean=240.9443, Std=363.9126
  personalized_feat - Shape: torch.Size([2, 1024]), Dtype: torch.float32, Device: cpu
  personalized_feat - Stats: Min=-26.4477, Max=3.0600, Mean=-0.0315, Std=0.9883
  emo_label - Shape: torch.Size([2]), Dtype: torch.int64, Values: [0, 0]

--- Analyzing Batch 1 ---
  A_feat - Shape: torch.Size([2, 26, 512]), Dtype: torch.float32, Device: cpu
  A_feat - Stats: Min=0.0000, Max=2.4135, Mean=0.0744, Std=0.1379
  V_feat - Shape: torch.Size([2, 26, 709]), Dtype: torch.float32, Device: cpu
  V_feat - Stats: Min=-117.1067, Max=1500.9800, Mean=257.6586, Std=385.2261
  personalized_feat - Shape: torch.Size([2, 1024]), Dtype: torch.float32, Device: cpu
  personalized_feat - Stats: Min=-26.4477, Max=3.0600, Mean=-0.0315, Std=0.9883
  emo_label - Shape: torch.Size([2]), Dtype: torch.int64, Values: [0, 0]

--- Analyzing Batch 2 ---
  A_feat - Shape: torch.Size([2, 26, 512]), Dtype: torch.float32, Device: cpu
  A_feat - Stats: Min=0.0000, Max=1.5717, Mean=0.0830, Std=0.1320
  V_feat - Shape: torch.Size([2, 26, 709]), Dtype: torch.float32, Device: cpu
  V_feat - Stats: Min=-103.5067, Max=1292.1466, Mean=298.0316, Std=350.1140
  personalized_feat - Shape: torch.Size([2, 1024]), Dtype: torch.float32, Device: cpu
  personalized_feat - Stats: Min=-26.5905, Max=2.8589, Mean=-0.0315, Std=0.9883
  emo_label - Shape: torch.Size([2]), Dtype: torch.int64, Values: [1, 1]

--- Analyzing Batch 3 ---
  A_feat - Shape: torch.Size([2, 26, 512]), Dtype: torch.float32, Device: cpu
  A_feat - Stats: Min=0.0000, Max=1.8335, Mean=0.0988, Std=0.1344
  V_feat - Shape: torch.Size([2, 26, 709]), Dtype: torch.float32, Device: cpu
  V_feat - Stats: Min=-129.8133, Max=1489.6666, Mean=357.7706, Std=384.0879
  personalized_feat - Shape: torch.Size([2, 1024]), Dtype: torch.float32, Device: cpu
  personalized_feat - Stats: Min=-26.5905, Max=2.8589, Mean=-0.0315, Std=0.9883
  emo_label - Shape: torch.Size([2]), Dtype: torch.int64, Values: [1, 1]

--- Analyzing Batch 4 ---
  A_feat - Shape: torch.Size([2, 26, 512]), Dtype: torch.float32, Device: cpu
  A_feat - Stats: Min=0.0000, Max=2.3058, Mean=0.0380, Std=0.1021
  V_feat - Shape: torch.Size([2, 26, 709]), Dtype: torch.float32, Device: cpu
  V_feat - Stats: Min=-159.6533, Max=1360.2600, Mean=185.7530, Std=326.9035
  personalized_feat - Shape: torch.Size([2, 1024]), Dtype: torch.float32, Device: cpu
  personalized_feat - Stats: Min=-27.5573, Max=2.5005, Mean=-0.0315, Std=0.9883
  emo_label - Shape: torch.Size([2]), Dtype: torch.int64, Values: [1, 1]

--- Analyzing Batch 5 ---
  A_feat - Shape: torch.Size([2, 26, 512]), Dtype: torch.float32, Device: cpu
  A_feat - Stats: Min=0.0000, Max=2.2672, Mean=0.0634, Std=0.1280
  V_feat - Shape: torch.Size([2, 26, 709]), Dtype: torch.float32, Device: cpu
  V_feat - Stats: Min=-111.6967, Max=1417.5100, Mean=260.2128, Std=352.5854
  personalized_feat - Shape: torch.Size([2, 1024]), Dtype: torch.float32, Device: cpu
  personalized_feat - Stats: Min=-27.5573, Max=2.7112, Mean=-0.0315, Std=0.9884
  emo_label - Shape: torch.Size([2]), Dtype: torch.int64, Values: [1, 1]

--- Analyzing Batch 6 ---
  A_feat - Shape: torch.Size([2, 26, 512]), Dtype: torch.float32, Device: cpu
  A_feat - Stats: Min=0.0000, Max=2.0377, Mean=0.0939, Std=0.1451
  V_feat - Shape: torch.Size([2, 26, 709]), Dtype: torch.float32, Device: cpu
  V_feat - Stats: Min=-118.8267, Max=1264.1233, Mean=320.6761, Std=350.1272
  personalized_feat - Shape: torch.Size([2, 1024]), Dtype: torch.float32, Device: cpu
  personalized_feat - Stats: Min=-27.4199, Max=2.7112, Mean=-0.0315, Std=0.9884
  emo_label - Shape: torch.Size([2]), Dtype: torch.int64, Values: [1, 1]

--- Analyzing Batch 7 ---
  A_feat - Shape: torch.Size([2, 26, 512]), Dtype: torch.float32, Device: cpu
  A_feat - Stats: Min=0.0000, Max=1.9819, Mean=0.0505, Std=0.1165
  V_feat - Shape: torch.Size([2, 26, 709]), Dtype: torch.float32, Device: cpu
  V_feat - Stats: Min=-106.5667, Max=1230.6083, Mean=168.4848, Std=298.5690
  personalized_feat - Shape: torch.Size([2, 1024]), Dtype: torch.float32, Device: cpu
  personalized_feat - Stats: Min=-27.4199, Max=3.1157, Mean=-0.0315, Std=0.9883
  emo_label - Shape: torch.Size([2]), Dtype: torch.int64, Values: [1, 0]

--- Analyzing Batch 8 ---
  A_feat - Shape: torch.Size([2, 26, 512]), Dtype: torch.float32, Device: cpu
  A_feat - Stats: Min=0.0000, Max=2.1704, Mean=0.0624, Std=0.1296
  V_feat - Shape: torch.Size([2, 26, 709]), Dtype: torch.float32, Device: cpu
  V_feat - Stats: Min=-98.9567, Max=1146.8625, Mean=229.6607, Std=329.2526
  personalized_feat - Shape: torch.Size([2, 1024]), Dtype: torch.float32, Device: cpu
  personalized_feat - Stats: Min=-26.5561, Max=3.1157, Mean=-0.0314, Std=0.9882
  emo_label - Shape: torch.Size([2]), Dtype: torch.int64, Values: [0, 0]

--- Analyzing Batch 9 ---
  A_feat - Shape: torch.Size([2, 26, 512]), Dtype: torch.float32, Device: cpu
  A_feat - Stats: Min=0.0000, Max=2.3789, Mean=0.0687, Std=0.1447
  V_feat - Shape: torch.Size([2, 26, 709]), Dtype: torch.float32, Device: cpu
  V_feat - Stats: Min=-109.9700, Max=1374.1633, Mean=264.9950, Std=350.2677
  personalized_feat - Shape: torch.Size([2, 1024]), Dtype: torch.float32, Device: cpu
  personalized_feat - Stats: Min=-27.3398, Max=3.1157, Mean=-0.0315, Std=0.9883
  emo_label - Shape: torch.Size([2]), Dtype: torch.int64, Values: [0, 0]

--- Input Data Inspection Summary ---
✅ OK: No NaN or Inf values found in 'A_feat' features within the first 10 batches checked.
   -> Stats Summary (A_feat): AvgMean=0.0698, AvgStd=0.1306, OverallMax=2.4519, OverallMin=0.0000
✅ OK: No NaN or Inf values found in 'V_feat' features within the first 10 batches checked.
   -> Stats Summary (V_feat): AvgMean=258.4187, AvgStd=349.1046, OverallMax=1500.9800, OverallMin=-159.6533
✅ OK: No NaN or Inf values found in 'personalized_feat' features within the first 10 batches checked.
   -> Stats Summary (personalized_feat): AvgMean=-0.0315, AvgStd=0.9883, OverallMax=3.1157, OverallMin=-27.5573

RECOMMENDATION: Based on checks of initial batches, input data appears numerically valid (no NaNs/Infs).
  - Check the value ranges reported in the stats summary. Are there extremely large/small values that could cause instability?
  - If ranges seem reasonable, the NaN issue likely originates *within* the model architecture (e.g., FiLM layer, attention) or hyperparameters (e.g., learning rate).
--- Inspection Complete ---
